{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Build parse data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fcc7247bf129d2a6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append('../../vietadminunits')\n",
    "from utils import to_alphanumeric, to_key"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Functions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f575361c4c167ffd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def add_province_key(df_province, province_english, province_key):\n",
    "    if not df_province[df_province.province_english==province_english].shape[0]:\n",
    "        raise ValueError(f'{province_english} is not exist in province_english')\n",
    "    elif df_province[(df_province.province_english==province_english) & (df_province.province_key==province_key)].shape[0]:\n",
    "        raise ValueError(f'{province_key} is exist in province_key')\n",
    "    \n",
    "    df_new = df_province.loc[df_province.province_english==province_english].head(1)\n",
    "    df_new['province_key'] = province_key\n",
    "    df_province = pd.concat([df_province, df_new])\n",
    "    return df_province"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c90c8f7661a749a1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def add_district_key(df_district, province_english, district_english, district_key):\n",
    "    if not df_district[df_district.province_english==province_english].shape[0]:\n",
    "        raise ValueError(f'{province_english} is not exist in province_english')\n",
    "    elif not df_district[(df_district.province_english==province_english) & (df_district.district_english==district_english)].shape[0]:\n",
    "        raise ValueError(f'{district_english} is not exist in district_english of {province_english}')\n",
    "    elif df_district[(df_district.province_english==province_english) & (df_district.district_english==district_english) & (df_district.district_key==district_key)].shape[0]:\n",
    "        raise ValueError(f'{district_key} is exist in district_key of {province_english}, {district_english}')\n",
    "    \n",
    "    df_new = df_district.loc[(df_district.province_english==province_english) & (df_district.district_english==district_english)].head(1)\n",
    "    df_new['district_key'] = district_key\n",
    "    df_district = pd.concat([df_district, df_new])\n",
    "    return df_district"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32b1939b896a8f98",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def add_ward_key(df_ward, province_english, district_english, ward_english, ward_key):\n",
    "    if not df_ward[df_ward.province_english==province_english].shape[0]:\n",
    "        raise ValueError(f'{province_english} is not exist in province_english')\n",
    "    \n",
    "    elif not df_ward[(df_ward.province_english==province_english) & (df_ward.district_english==district_english)].shape[0]:\n",
    "        raise ValueError(f'{district_english} is not exist in district_english of {province_english}')\n",
    "    \n",
    "    elif not df_ward[(df_ward.province_english==province_english) & (df_ward.district_english==district_english) & (df_ward.ward_english==ward_english)].shape[0]:\n",
    "        raise ValueError(f'{ward_english} is not exist in ward_english of {province_english}, {district_english}')\n",
    "    \n",
    "    elif df_ward[(df_ward.province_english==province_english) & (df_ward.district_english==district_english) & (df_ward.ward_english==ward_english) & (df_ward.ward_key==ward_key)].shape[0]:\n",
    "        raise ValueError(f'{ward_key} is exist in ward_key of {province_english}, {district_english}, {ward_english}')\n",
    "    \n",
    "    df_new = df_ward.loc[(df_ward.province_english==province_english) & (df_ward.district_english==district_english) & (df_ward.ward_english==ward_english)].head(1)\n",
    "    df_new['ward_key'] = ward_key\n",
    "    df_ward = pd.concat([df_ward, df_new])\n",
    "    return df_ward"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f4875c92642bdac",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be8d4555bb973d69"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/output/vietnam_administrative_units.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3dd43d782abe18a1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e537352f45630d46",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c7865b3c62ec036",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create keyword columns and fillna NULL columns"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4abca40454b4b073"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df['province_key'] = df['province'].apply(to_key, args=(1,))\n",
    "df['district_key'] = df['short_district'].apply(to_key, args=(2,))\n",
    "df['ward_key'] = df['short_ward'].apply(to_key, args=(3,))\n",
    "df['district_level_english'].fillna('', inplace=True)\n",
    "df['ward_level_english'].fillna('', inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c5d99ae8b4ce619",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create keyword lists that are duplicated district_keyword"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "635b3efaecaa2f6e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "district_count = df[['province', 'long_district', 'district_key']].drop_duplicates()[['province', 'district_key']].value_counts().reset_index()\n",
    "duplicated_districts = district_count[district_count['count'] > 1]['district_key'].tolist()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5ac0bb1ca84818b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_duplicated_districts = df[df.district_key.isin(duplicated_districts)][['long_province', 'long_district' ,'province_key','district_key']].drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c19e9d87e6f766ee",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_duplicated_districts"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "20495c948239a612",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Idea: Use their ward_key if possible\n",
    "for district_key in duplicated_districts:\n",
    "    long_districts = df[df.district_key==district_key]['long_district'].unique().tolist()\n",
    "    a = []\n",
    "    b = []\n",
    "    long_district_a = long_districts[0]\n",
    "    long_district_b = long_districts[1]\n",
    "    ward_key_a = df[df.long_district==long_district_a]['ward_key'].unique().tolist()\n",
    "    ward_key_b = df[df.long_district==long_district_b]['ward_key'].unique().tolist()\n",
    "    common = list(set(a) & set(b))\n",
    "    if common:\n",
    "        print(district_key, 'has duplicated ward_key')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e01c31372792a7a0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Pickle\n",
    "# Use Google Trend and search to decide level\n",
    "duplicated_district_province_keys = df_duplicated_districts['province_key'].unique().tolist()\n",
    "\n",
    "duplicated_district_keys = {\n",
    "    'kyanh': {'default':'Town'},\n",
    "    'cailay': {'default':'Town'},\n",
    "    'duyenhai': {'default':'District'},\n",
    "    'caolanh': {'default':'City'},\n",
    "    'hongngu': {'default':'City'},\n",
    "    'longmy': {'default':'District'}\n",
    "}\n",
    "\n",
    "for district_key in duplicated_districts:\n",
    "    df_temp = df[df.district_key == district_key]\n",
    "    level_data = {}\n",
    "    levels = df_temp.district_level_english.unique().tolist()\n",
    "    for district_level_english in levels:\n",
    "        ward_keys = df_temp[df_temp.district_level_english==district_level_english]['ward_key'].unique().tolist()\n",
    "        level_data[district_level_english] = ward_keys\n",
    "        duplicated_district_keys[district_key]['levels'] = level_data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ebaf93ff2e5143f8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print('Provinces:', duplicated_district_province_keys)\n",
    "print('Districts:', duplicated_district_keys)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "969432cad1a18d05",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Pickle\n",
    "half_district_keys = {'mocay': {'mocaynam': ['mocay',\n",
    "   'dinhthuy',\n",
    "   'daphuochoi',\n",
    "   'tanhoi',\n",
    "   'phuochiep',\n",
    "   'binhkhanh',\n",
    "   'anthanh',\n",
    "   'andinh',\n",
    "   'thanhthoib',\n",
    "   'tantrung',\n",
    "   'anthoi',\n",
    "   'thanhthoia',\n",
    "   'minhduc',\n",
    "   'ngaidang',\n",
    "   'camson',\n",
    "   'huongmy'],\n",
    "  'mocaybac': ['phumy',\n",
    "   'hungkhanhtrunga',\n",
    "   'thanhtan',\n",
    "   'thanhngai',\n",
    "   'tanphutay',\n",
    "   'phuocmytrung',\n",
    "   'tanthanhbinh',\n",
    "   'thanhan',\n",
    "   'hoaloc',\n",
    "   'tanthanhtay',\n",
    "   'tanbinh',\n",
    "   'nhuanphutan',\n",
    "   'khanhthanhtan']},\n",
    " 'hamthuan': {'hamthuanbac': ['malam',\n",
    "   'phulong',\n",
    "   'lada',\n",
    "   'dongtien',\n",
    "   'thuanhoa',\n",
    "   'donggiang',\n",
    "   'hamphu',\n",
    "   'hongliem',\n",
    "   'thuanminh',\n",
    "   'hongson',\n",
    "   'hamtri',\n",
    "   'hamduc',\n",
    "   'hamliem',\n",
    "   'hamchinh',\n",
    "   'hamhiep',\n",
    "   'hamthang',\n",
    "   'dami'],\n",
    "  'hamthuannam': ['thuannam',\n",
    "   'mythanh',\n",
    "   'hamcan',\n",
    "   'muongman',\n",
    "   'hamthanh',\n",
    "   'hamkiem',\n",
    "   'hamcuong',\n",
    "   'hammy',\n",
    "   'tanlap',\n",
    "   'hamminh',\n",
    "   'thuanquy',\n",
    "   'tanthuan',\n",
    "   'tanthanh']},\n",
    " 'tuliem': {'namtuliem': ['caudien',\n",
    "   'xuanphuong',\n",
    "   'phuongcanh',\n",
    "   'mydinh1',\n",
    "   'mydinh2',\n",
    "   'taymo',\n",
    "   'metri',\n",
    "   'phudo',\n",
    "   'daimo',\n",
    "   'trungvan'],\n",
    "  'bactuliem': ['thuongcat',\n",
    "   'lienmac',\n",
    "   'dongngac',\n",
    "   'ducthang',\n",
    "   'thuyphuong',\n",
    "   'taytuu',\n",
    "   'xuandinh',\n",
    "   'xuantao',\n",
    "   'minhkhai',\n",
    "   'conhue1',\n",
    "   'conhue2',\n",
    "   'phudien',\n",
    "   'phucdien']},\n",
    " 'tramy': {'bactramy': ['tramy',\n",
    "   'trason',\n",
    "   'trakot',\n",
    "   'tranu',\n",
    "   'tradong',\n",
    "   'traduong',\n",
    "   'tragiang',\n",
    "   'trabui',\n",
    "   'tradoc',\n",
    "   'tratan',\n",
    "   'tragiac',\n",
    "   'tragiap',\n",
    "   'traka'],\n",
    "  'namtramy': ['traleng',\n",
    "   'tradon',\n",
    "   'tratap',\n",
    "   'tramai',\n",
    "   'tracang',\n",
    "   'tralinh',\n",
    "   'tranam',\n",
    "   'travan',\n",
    "   'travinh']},\n",
    " 'gocong': {'gocong': ['phuong2',\n",
    "   'phuong1',\n",
    "   'phuong5',\n",
    "   'longhung',\n",
    "   'longthuan',\n",
    "   'longchanh',\n",
    "   'longhoa',\n",
    "   'binhdong',\n",
    "   'binhxuan',\n",
    "   'tantrung'],\n",
    "  'gocongtay': ['vinhbinh',\n",
    "   'dongson',\n",
    "   'binhphu',\n",
    "   'dongthanh',\n",
    "   'thanhcong',\n",
    "   'binhnhi',\n",
    "   'yenluong',\n",
    "   'thanhtri',\n",
    "   'thanhnhut',\n",
    "   'longvinh',\n",
    "   'binhtan',\n",
    "   'vinhhuu',\n",
    "   'longbinh'],\n",
    "  'gocongdong': ['tanhoa',\n",
    "   'tanghoa',\n",
    "   'tanphuoc',\n",
    "   'giathuan',\n",
    "   'vamlang',\n",
    "   'tantay',\n",
    "   'kiengphuoc',\n",
    "   'tandong',\n",
    "   'binhan',\n",
    "   'tandien',\n",
    "   'binhnghi',\n",
    "   'phuoctrung',\n",
    "   'tanthanh']}}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8eac82ca3882d06c",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create keyword lists that are duplicated ward_keyword"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b2e02ce611ed152"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ward_count = df[['long_province', 'long_district', 'short_ward']].value_counts().reset_index()\n",
    "df_duplicated_wards = ward_count[ward_count['count'] > 1].copy()\n",
    "df_duplicated_wards.sort_values(by=['long_province', 'long_district', 'short_ward'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36d6afa7d76816ea",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_duplicated_wards = df[(df.long_province.isin(df_duplicated_wards.long_province)) & (df.long_district.isin(df_duplicated_wards.long_district)) & (df.short_ward.isin(df_duplicated_wards.short_ward))][['province', 'long_district', 'ward','ward_level_english', 'district_key', 'ward_key']]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d92faf473be44bb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_duplicated_wards"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22024ec0b6c0c44f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Following Google Trend, \"xã ...\" is higher \"thị trấn ...\" significant. But \"phường ...\" is higher than \"xã ...\" and we have only one ward in the list."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae2dd5d209a6b301"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Pickle\n",
    "duplicated_ward_keys = df_duplicated_wards.ward_key.unique().tolist()\n",
    "duplicated_ward_district_keys = df_duplicated_wards.district_key.unique().tolist()\n",
    "\n",
    "new_data = {}\n",
    "\n",
    "for ward_key in duplicated_ward_keys:\n",
    "    levels = df_duplicated_wards[df_duplicated_wards.ward_key == ward_key]['ward_level_english'].tolist()\n",
    "    if 'Ward' in levels:\n",
    "        ward_level = 'Ward'\n",
    "    elif 'Commune' in levels:\n",
    "        ward_level = 'Commune'\n",
    "    else:\n",
    "        ward_level = 'Town'\n",
    "    new_data[ward_key] = ward_level\n",
    "    \n",
    "duplicated_ward_keys = new_data.copy()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b25c9f8f0985e16",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print('Districts:' ,duplicated_ward_district_keys)\n",
    "print('Wards:', duplicated_ward_keys)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2e88418396fed1f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sort province_key to prioritize some provinces\n",
    "- Some province has districts, or wards that are the same keyword with another province.\n",
    "- We need to run module_testing to check whether any address is wrong > Use ChatGPT to sort keywords > Add manually if we found new wrong keyword.\n",
    "\n",
    "For example:\n",
    "- 'Huyện Quang Bình, Tỉnh Hà Giang' -> quangbinh\n",
    "- 'Huyện Phù Yên, Tỉnh Sơn La' -> phuyen\n",
    "- 'Huyện Văn Giang, Tỉnh Hưng Yên' -> angiang\n",
    "- 'Huyện Quảng Ninh, Tỉnh Quảng Bình' -> quangninh\n",
    "- Bac Lieu, Hoa Binh District -> hoabinh"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1e920e2186097aa"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "province_keys = df.province_key.unique().tolist()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55326a74baf22559",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def find_province_key_match(text):\n",
    "    for province_key in province_keys:\n",
    "        if province_key in text:\n",
    "            return province_key"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3eab46036d6d2a6c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "match_district = df[df.district_key.str.contains('|'.join(province_keys))][['province', 'district', 'province_key','district_key']].drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "349b471c9a67b87a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "match_ward = df[(~df.ward.isna()) & (df.ward_key.str.contains('|'.join(province_keys)))][['province', 'ward', 'province_key','ward_key']].drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2101b458daa5bb6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "match_district['match_province_key'] = match_district['district_key'].apply(find_province_key_match)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7a235615b092279",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "match_ward['match_province_key'] = match_ward['ward_key'].apply(find_province_key_match)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90a5364c7d279ffa",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "match_district = match_district[match_district.province_key != match_district.match_province_key]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2e38920a24963e7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "match_district"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd8f0dcf755e4a76",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "match_ward = match_ward[match_ward.province_key != match_ward.match_province_key]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e8dabbad58575bc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "match_ward"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a286547162f15df7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Should not use list(set()) because it will re-order\n",
    "province_order = []\n",
    "\n",
    "for row in match_district.itertuples():\n",
    "    if row.province_key not in province_order:\n",
    "        province_order.append(row.province_key)\n",
    "    if row.match_province_key not in province_order:\n",
    "        province_order.append(row.match_province_key)\n",
    "        \n",
    "for row in match_ward.itertuples():\n",
    "    if row.province_key not in province_order:\n",
    "        province_order.append(row.province_key)\n",
    "    if row.match_province_key not in province_order:\n",
    "        province_order.append(row.match_province_key)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c8687cc82b480bf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "province_key_order = {}\n",
    "for index, province_key in enumerate(province_order):\n",
    "    province_key_order[province_key] = index + 1\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5129d80c0bf4f652",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(province_key_order)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21551ef031d6de7b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df['province_key_order'] = df['province_key'].map(province_key_order).fillna(0)\n",
    "\n",
    "df.sort_values(by='province_key_order', inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8a12456da334b0",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Add alias province_keyword\n",
    "- We should not add \"hn\" because it will cause many wrong matches. I will replace `\\bhn\\b` to `\\bha noi\\b` of the address, this step is in `parse.py`"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "398029c04e639d54"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_province = df[[col for col in df.columns if 'province' in col]].drop_duplicates()\n",
    "\n",
    "province_alias_keys = [\n",
    "    ('Ho Chi Minh', 'hcm')\n",
    "]\n",
    "\n",
    "for key in province_alias_keys:\n",
    "    province_english, province_key = key\n",
    "    df_province = add_province_key(df_province, province_english, province_key)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e3e541cf6cffa27",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Add alias district_keyword\n",
    "There are many district was changed it's name or be combined with other districts. For instance: Quan 9 > Thanh pho Thu Duc.\n",
    "\n",
    "Use `find_district_alias_keywords.ipynb` to create a list of tuples."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7bc50feab7e6e99d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_district = df[['province_english'] + [col for col in df.columns if 'district' in col]].drop_duplicates()\n",
    "\n",
    "district_alias_keys = [\n",
    "    ('An Giang', 'Chau Thanh', 'hueduc'),\n",
    "    ('Ba Ria - Vung Tau', 'Phu My', 'tanthanh'),\n",
    "    ('Bac Kan', 'Ba Be', 'chora'),\n",
    "    ('Bac Lieu', 'Bac Lieu', 'minhhai'),\n",
    "    ('Binh Duong', 'Tan Uyen', 'chauthanh'),\n",
    "    ('Binh Duong', 'Thuan An', 'laithieu'),\n",
    "    ('Binh Phuoc', 'Phuoc Long', 'phuocbinh'),\n",
    "    ('Ca Mau', 'Dam Doi', 'ngochien'),\n",
    "    ('Cao Bang', 'Quang Hoa', 'phuchoa'),\n",
    "    ('Cao Bang', 'Quang Hoa', 'quanguyen'),\n",
    "    ('Cao Bang', 'Ha Quang', 'thongnong'),\n",
    "    ('Cao Bang', 'Trung Khanh', 'tralinh'),\n",
    "    ('Dien Bien', 'Muong Lay', 'laichau'),\n",
    "    ('Dien Bien', 'Muong Cha', 'muonglay'),\n",
    "    ('Dong Nai', 'Vinh Cuu', 'vinhan'),\n",
    "    ('Dong Thap', 'Lap Vo', 'thanhhung'),\n",
    "    ('Ha Nam', 'Phu Ly', 'hanam'),\n",
    "    ('Ha Noi', 'Soc Son', 'daphuc'),\n",
    "    ('Ha Noi', 'Soc Son', 'kimanh'),\n",
    "    ('Hai Phong', 'Cat Hai', 'catba'),\n",
    "    ('Hau Giang', 'Vi Thanh', 'mythanh'),\n",
    "    ('Hau Giang', 'Nga Bay', 'tanhiep'),\n",
    "    ('Hoa Binh', 'Hoa Binh', 'kyson'),\n",
    "    ('Khanh Hoa', 'Dien Khanh', 'khanhxuong'),\n",
    "    ('Kien Giang', 'Kien Luong', 'hatien'),\n",
    "    ('Lao Cai', 'Lao Cai', 'camduong'),\n",
    "    ('Nam Dinh', 'Nam Dinh', 'myloc'),\n",
    "    ('Ninh Binh', 'Hoa Lu', 'giakhanh'),\n",
    "    ('Ninh Binh', 'Nho Quan', 'hoanglong'),\n",
    "    ('Ninh Binh', 'Yen Mo', 'tamdiep'),\n",
    "    ('Phu Tho', 'Cam Khe', 'songthao'),\n",
    "    ('Quang Nam', 'Nam Giang', 'giang'),\n",
    "    ('Quang Ngai', 'Tra Bong', 'taytra'),\n",
    "    ('Quang Ninh', 'Ha Long', 'honggai'),\n",
    "    ('Quang Ninh', 'Van Don', 'campha'),\n",
    "    ('Quang Ninh', 'Mong Cai', 'haininh'),\n",
    "    ('Quang Ninh', 'Quang Yen', 'yenhung'),\n",
    "    ('Quang Ninh', 'Ha Long', 'hoanhbo'),\n",
    "    ('Tay Ninh', 'Hoa Thanh', 'phukhuong'),\n",
    "    ('Thanh Hoa', 'Dong Son', 'dongthieu'),\n",
    "    ('Thanh Hoa', 'Yen Dinh', 'thieuyen'),\n",
    "    ('Thanh Hoa', 'Nghi Son', 'tinhgia'),\n",
    "    ('Ho Chi Minh', 'Can Gio', 'duyenhai'),\n",
    "    ('Ho Chi Minh', 'Thu Duc', 'quan2'),\n",
    "    ('Ho Chi Minh', 'Thu Duc', 'quan9'),\n",
    "    # ('Ho Chi Minh', 'Thu Duc', 'thuduc(quan)'),\n",
    "    ('Tra Vinh', 'Cang Long', 'chauthanhdong'),\n",
    "    ('Vinh Long', 'Long Ho', 'cainhum'),\n",
    "    ('Vinh Long', 'Long Ho', 'chauthanhtay'),\n",
    "    ('Ben Tre', 'Mo Cay Nam', 'mocay'),\n",
    "    ('Binh Thuan', 'Ham Thuan Nam', 'hamthuan'),\n",
    "    ('Ha Noi', 'Nam Tu Liem', 'tuliem'),\n",
    "    ('Quang Nam', 'Nam Tra My', 'tramy'),\n",
    "    ('Tien Giang', 'Go Cong Tay', 'gocong')\n",
    "\n",
    "]\n",
    "\n",
    "for key in district_alias_keys:\n",
    "    province_english, district_english, district_key = key\n",
    "    df_district = add_district_key(df_district, province_english, district_english, district_key)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b4ed620017edf0a",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some districts contain \"quan\" with number in their keywords. We need to make a copy and replace \"quan\" to \"district\"."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "329dfb4242377ef8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "hcm_districts = df_district[df_district['district_key'].str.contains(r'quan\\d{1,2}')].copy()\n",
    "hcm_districts['district_key'] = hcm_districts['district_key'].str.replace('quan', 'district')\n",
    "df_district = pd.concat([df_district, hcm_districts])\n",
    "hcm_districts['district_key'] = hcm_districts['district_key'].str.replace('district', 'q.')\n",
    "df_district = pd.concat([df_district, hcm_districts])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e3870492482a94a",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create alias ward_key\n",
    "Some wards contain \"phuong\" with number in their keywords. We need to make a copy and replace \"phuong\" to \"ward\".\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5cb518d7ed6fa887"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_ward = df[['province_english', 'district_english'] + [col for col in df.columns if 'ward' in col]].drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e14acc61d1d33a8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "number_wards = df_ward[df_ward['ward_key'].fillna('').str.contains(r'phuong\\d{1,2}')].copy()\n",
    "number_wards['ward_key'] = number_wards['ward_key'].str.replace('phuong', 'ward')\n",
    "df_ward = pd.concat([df_ward, number_wards])\n",
    "number_wards['ward_key'] = number_wards['ward_key'].str.replace('ward', 'p.')\n",
    "df_ward = pd.concat([df_ward, number_wards])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7e66b3d54b9f90d",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create province_keys lists\n",
    "We will prioritize provinces that are not in district_key or ward_key when searching a province_key in address."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50bfaf3078fc1682"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "province_keys = df_province['province_key'].tolist()\n",
    "\n",
    "# Pickle\n",
    "province_keys_1 = []\n",
    "province_keys_2 = []\n",
    "province_keys_3 = []\n",
    "\n",
    "district_keys = str(df.district_key.unique().tolist())\n",
    "ward_keys = str(df.ward_key.unique().tolist())\n",
    "for province_key in province_keys:\n",
    "    if (province_key not in district_keys) and (province_key not in ward_keys):\n",
    "        province_keys_1.append(province_key)\n",
    "    elif province_key not in ward_keys:\n",
    "        province_keys_2.append(province_key)\n",
    "    else:\n",
    "        province_keys_3.append(province_key)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1b5241edd87bf58",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create mapping dictionaries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa791b0587c8590a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Pickle\n",
    "province_map = {}\n",
    "\n",
    "for province_key in df_province.province_key.unique():\n",
    "    province = df_province[df_province['province_key'] == province_key]\n",
    "    province_record = province.to_dict(orient='records')[0]\n",
    "    province_map[province_key] = province_record"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dcb40691af26b797",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(province_map)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "655b12be0a2ce88a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Pickle\n",
    "district_map = {}\n",
    "\n",
    "for province_english in df_province.province_english.unique():\n",
    "    district_keys = {}\n",
    "    for district_key in df_district[df_district.province_english == province_english]['district_key'].unique():\n",
    "        district_levels = {}\n",
    "        for district_level_english in df_district[(df_district.province_english == province_english) & (df_district.district_key == district_key)]['district_level_english'].unique():\n",
    "            district = df_district[(df_district.province_english == province_english) & (df_district.district_key == district_key) & (df_district.district_level_english == district_level_english)]\n",
    "            district_record = district[[col for col in district.columns if 'district' in col]].to_dict('records')[0]\n",
    "            district_levels[district_level_english] = district_record\n",
    "        district_keys[district_key] = district_levels\n",
    "        \n",
    "    district_keys = dict(sorted(district_keys.items(), key=lambda item: len(item[0]), reverse=True))\n",
    "    \n",
    "    district_map[province_english] = district_keys"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "57ab1579066f41f5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(district_map['Ho Chi Minh'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "caddace33c6defe9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Pickle\n",
    "ward_map = {}\n",
    "\n",
    "for province_english in df_province.province_english.unique():\n",
    "    districts = {}\n",
    "    for district_english in df_district[df_district.province_english==province_english].district_english.unique():\n",
    "        wards = {}\n",
    "        for ward_key in df_ward[(df_ward.province_english==province_english) & (df_ward.district_english==district_english)].ward_key.dropna().unique():\n",
    "            ward_levels = {}\n",
    "            for ward_level_english in df_ward[(df_ward.province_english==province_english) & (df_ward.district_english==district_english) & (df_ward.ward_key==ward_key)].ward_level_english.unique():\n",
    "                ward = df_ward[(df_ward.province_english==province_english) & (df_ward.district_english==district_english) & (df_ward.ward_key==ward_key) & (df_ward.ward_level_english==ward_level_english)]\n",
    "                ward_record = ward[[col for col in ward.columns if 'ward' in col]].to_dict('records')[0]\n",
    "                ward_levels[ward_level_english] = ward_record\n",
    "            wards[ward_key] = ward_levels\n",
    "        wards = dict(sorted(wards.items(), key=lambda item: len(str(item[0])), reverse=True))\n",
    "        districts[district_english] = wards\n",
    "    ward_map[province_english] = districts"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0eceda7e27b697e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(ward_map['Ho Chi Minh']['Tan Binh'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c78473258c2ed315",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create double check dictionaries\n",
    "Some address will cause wrong mapping because they have ward_key is as same as other province's province_key."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e9f3c281b5238c9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "double_check_provinces = {\n",
    "    'angiang': ['thainguyen', 'ninhbinh', 'thanhhoa'],\n",
    "    'hoabinh': ['thainguyen',\n",
    "    'langson',\n",
    "    'haiphong',\n",
    "    'thaibinh',\n",
    "    'dongnai',\n",
    "    'vinhlong',\n",
    "    'dongthap'],\n",
    "    'binhthuan': ['thainguyen', 'quangngai', 'binhdinh'],\n",
    "    'thanhhoa': ['langson', 'binhphuoc', 'travinh', 'kiengiang', 'haugiang'],\n",
    "    'thaibinh': ['langson', 'tayninh'],\n",
    "    'hagiang': ['thaibinh', 'thanhhoa'],\n",
    "    'quangbinh': ['thaibinh', 'thanhhoa'],\n",
    "    'sonla': ['ninhbinh', 'quangngai', 'khanhhoa'],\n",
    "    'khanhhoa': ['ninhbinh', 'kiengiang'],\n",
    "    'longan': ['thanhhoa', 'dongnai', 'vinhlong'],\n",
    "    'quangninh': ['thanhhoa'],\n",
    "    'vinhlong': ['quangtri'],\n",
    "    'haiduong': ['quangtri'],\n",
    "    'haiphong': ['quangtri'],\n",
    "    'binhduong': ['quangnam', 'quangngai', 'binhdinh'],\n",
    "    'binhdinh': ['quangnam'],\n",
    "    'hungyen': ['kiengiang']\n",
    "}\n",
    "\n",
    "# double_check_provinces = {} # testing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "583daf5f5624ebf6",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some address will cause wrong mapping because they have ward_key is as same as other district's district_key."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ce87f2d7eddb04a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "double_check_districts = {'unghoa': ['caugiay', 'chuongmy'],\n",
    " 'thanhtri': ['hoangmai'],\n",
    " 'thanhxuan': ['socson'],\n",
    " 'thanhoai': ['thanhtri'],\n",
    " 'thongnong': ['haquang'],\n",
    " 'tralinh': ['trungkhanh'],\n",
    " 'quanguyen': ['quanghoa'],\n",
    " 'chora': ['babe'],\n",
    " 'yenson': ['sonduong'],\n",
    " 'camduong': ['laocai'],\n",
    " 'muongla': ['phuyen', 'songma', 'sopcop'],\n",
    " 'tranyen': ['lucyen', 'yenbinh'],\n",
    " 'kyson': ['hoabinh', 'tanky'],\n",
    " 'chilang': ['langson', 'trangdinh'],\n",
    " 'honggai': ['halong'],\n",
    " 'hoanhbo': ['halong'],\n",
    " 'uongbi': ['mongcai'],\n",
    " 'halong': ['vandon'],\n",
    " 'haiduong': ['binhgiang'],\n",
    " 'anduong': ['lechan', 'duongkinh', 'thuynguyen', 'vinhbao'],\n",
    " 'catba': ['cathai'],\n",
    " 'phucu': ['hungyen'],\n",
    " 'myloc': ['namdinh'],\n",
    " 'dongson': ['thanhhoa', 'bimson'],\n",
    " 'hatrung': ['bathuoc'],\n",
    " 'thanhhoa': ['nhuxuan', 'benluc'],\n",
    " 'vinh': ['anhson', 'yenthanh', 'hoangmai'],\n",
    " 'yenthanh': ['thanhchuong'],\n",
    " 'anhson': ['thanhchuong', 'namdan'],\n",
    " 'thachha': ['hatinh'],\n",
    " 'huongthuy': ['hue'],\n",
    " 'giang': ['thangbinh', 'bactramy', 'nuithanh'],\n",
    " 'tramy': ['bactramy'],\n",
    " 'sontinh': ['sontay'],\n",
    " 'ducpho': ['moduc'],\n",
    " 'dakto': ['konray', 'tumorong'],\n",
    " 'dakha': ['tumorong'],\n",
    " 'dakpo': ['kongchro'],\n",
    " 'iapa': ['chuse'],\n",
    " 'krongbuk': ['krongpac'],\n",
    " 'phuocbinh': ['phuoclong'],\n",
    " 'hoathanh': ['chauthanh'],\n",
    " 'laithieu': ['thuanan'],\n",
    " 'thongnhat': ['bienhoa'],\n",
    " 'vinhan': ['vinhcuu'],\n",
    " 'binhchanh': ['thuduc'],\n",
    " 'tanphu': ['thuduc', 'quan7', 'cuchi'],\n",
    " 'tanthanh': ['mochoa', 'thuthua'],\n",
    " 'tanan': ['canduoc'],\n",
    " 'tanhung': ['chauthanh'],\n",
    " 'tanphuoc': ['gocongdong'],\n",
    " 'mocay': ['mocaynam'],\n",
    " 'thanhphu': ['giongtrom', 'binhdai'],\n",
    " 'cainhum': ['mangthit'],\n",
    " 'longho': ['mangthit'],\n",
    " 'chauphu': ['chaudoc'],\n",
    " 'anphu': ['phutan', 'tinhbien', 'chauthanh', 'thoaison'],\n",
    " 'anminh': ['chauthanh', 'uminhthuong'],\n",
    " 'vithanh': ['vithuy']}\n",
    "\n",
    "# double_check_districts = {} # tesing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e838dbdf6fd290df",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Support find province from unique districts\n",
    "\n",
    "Điều kiện 1: district_key not in ward_keys.\n",
    "Điều kiện 2: district_count = 1, sau khi đã drop_duplicated [province_key, district_key]\n",
    "Điều kiện 3: district_key not in province_keys của tỉnh khác.\n",
    "\n",
    "Nếu district_key = province_key của chính nó:\n",
    ">> Lấy danh sách long_district_alphanumerices (bao gồm Việt và English), nếu tồn tại trong address thì sau khi tìm được province_key sẽ không bị xóa province_key trong địa chỉ.\n",
    "\n",
    "\n",
    "Nếu district_key != province_key của chính nó, tức là unique tuyệt đối:\n",
    ">> Lấy danh sách unique_district_keys, nếu không tìm được province_key thì tìm unique_district_key để suy ngược ra province_key"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d73800f8313ff044"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/output/vietnam_administrative_units.csv')\n",
    "df['province_key'] = df['province'].apply(lambda x: to_key(x, 1))\n",
    "df['district_key'] = df['short_district'].apply(lambda x: to_key(x, 2))\n",
    "df['ward_key'] = df['short_ward'].apply(lambda x: to_key(x, 3))\n",
    "\n",
    "province_keys = df['province_key'].unique().tolist()\n",
    "district_keys = df['district_key'].unique().tolist()\n",
    "ward_keys = df['ward_key'].unique().tolist()\n",
    "\n",
    "df_district_filter = df[~df.district_key.isin(ward_keys)]\n",
    "df_district_filter_count = df_district_filter[['province_key', 'district_key']].drop_duplicates()['district_key'].value_counts().reset_index()\n",
    "one_district_keys = df_district_filter_count[df_district_filter_count['count']==1]['district_key'].tolist()\n",
    "df_district_filter = df_district_filter[df_district_filter.district_key.isin(one_district_keys)][['province_key', 'district_key', 'long_district', 'long_district_english']].drop_duplicates()\n",
    "\n",
    "def check_valid_district_key(district_key, province_key):\n",
    "    if district_key in province_keys and district_key != province_key:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "df_district_filter['is_valid_district_key'] = df_district_filter.apply(lambda x: check_valid_district_key(x['district_key'], x['province_key']), axis=1)\n",
    "df_district_filter = df_district_filter[df_district_filter.is_valid_district_key]\n",
    "df_district_filter['same_key'] = np.where(df_district_filter.province_key == df_district_filter.district_key, True, False)\n",
    "\n",
    "long_district_alphanumerics = []\n",
    "for row in df_district_filter[df_district_filter.same_key].itertuples():\n",
    "    long_district_alphanumerics.append(to_alphanumeric(row.long_district))\n",
    "    long_district_alphanumerics.append(to_alphanumeric(row.long_district).replace('thanhpho', 'tp.'))\n",
    "    long_district_alphanumerics.append(to_alphanumeric(row.long_district_english))\n",
    "    \n",
    "    \n",
    "unique_district_keys = {}\n",
    "for row in df_district_filter[~df_district_filter.same_key][['province_key', 'district_key']].drop_duplicates().itertuples():\n",
    "    unique_district_keys[row.district_key] = row.province_key\n",
    "    district_key = row.district_key\n",
    "    if re.search(r'^quan\\d{1,2}', district_key):\n",
    "        district_key = re.sub('^quan', 'q.', district_key)\n",
    "        unique_district_keys[district_key] = row.province_key"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2b4db8bf5dd5cfd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "len(long_district_alphanumerics)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f091f2a7f8420957",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "long_district_alphanumerics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2acdb3e7cd4f9e7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "len(unique_district_keys)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9607ff5a96564e72",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "unique_district_keys"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7daef7760b5a49eb",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Support find province from unique \"long\" districts"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f14467c7737f6b9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df['province_alphanumeric'] = df['long_province'].apply(to_alphanumeric)\n",
    "df['district_alphanumeric'] = df['long_district'].apply(to_alphanumeric)\n",
    "df['district_alphanumeric_english'] = df['long_district_english'].apply(to_alphanumeric)\n",
    "df['ward_alphanumeric'] = df['long_ward'].apply(to_alphanumeric)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a667c0208b841f2b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "province_alphanumerics = df['province_alphanumeric'].unique().tolist()\n",
    "district_alphanumerics = df['district_alphanumeric'].unique().tolist()\n",
    "ward_alphanumerics = df['ward_alphanumeric'].unique().tolist()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e931e01409036401",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_district_filter = df[~df.district_alphanumeric.isin(ward_alphanumerics)]\n",
    "df_district_filter_count = df_district_filter[['province_alphanumeric', 'district_alphanumeric']].drop_duplicates()['district_alphanumeric'].value_counts().reset_index()\n",
    "one_district_alphanumerics = df_district_filter_count[df_district_filter_count['count']==1]['district_alphanumeric'].tolist()\n",
    "df_district_filter = df_district_filter[df_district_filter.district_alphanumeric.isin(one_district_alphanumerics)][['province_key','province_alphanumeric', 'district_alphanumeric', 'long_district', 'long_district_english', 'district_key', 'district_alphanumeric_english']].drop_duplicates()\n",
    "\n",
    "def check_valid_district_alphanumeric(district_alphanumeric, province_alphanumeric):\n",
    "    if district_alphanumeric in province_alphanumerics and district_alphanumeric != province_alphanumeric:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "df_district_filter['is_valid_district_alphanumeric'] = df_district_filter.apply(lambda x: check_valid_district_alphanumeric(x['district_alphanumeric'], x['province_alphanumeric']), axis=1)\n",
    "df_district_filter = df_district_filter[df_district_filter.is_valid_district_alphanumeric]\n",
    "df_district_filter['same_alphanumeric'] = np.where(df_district_filter.province_alphanumeric == df_district_filter.district_alphanumeric, True, False)\n",
    "\n",
    "for row in df_district_filter[df_district_filter.same_alphanumeric].itertuples():\n",
    "    long_district_alphanumerics.append(to_alphanumeric(row.long_district))\n",
    "    long_district_alphanumerics.append(to_alphanumeric(row.long_district).replace('thanhpho', 'tp.'))\n",
    "    long_district_alphanumerics.append(to_alphanumeric(row.long_district_english))\n",
    "    \n",
    "    \n",
    "for row in df_district_filter[~df_district_filter.same_alphanumeric][['province_key', 'district_alphanumeric', 'district_key', 'district_alphanumeric_english']].drop_duplicates().itertuples():\n",
    "    if not row.district_key in unique_district_keys:\n",
    "        unique_district_keys[row.district_alphanumeric] = row.province_key\n",
    "        unique_district_keys[row.district_alphanumeric_english] = row.province_key\n",
    "        district_alphanumeric = row.district_alphanumeric\n",
    "        district_alphanumeric = re.sub('^quan', 'q.', district_alphanumeric)\n",
    "        district_alphanumeric = re.sub('^huyen', 'h.', district_alphanumeric)\n",
    "        district_alphanumeric = re.sub('^thanhpho', 'tp.', district_alphanumeric)\n",
    "        district_alphanumeric = re.sub('^thixa', 'tx.', district_alphanumeric)\n",
    "        unique_district_keys[district_alphanumeric] = row.province_key"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65d5d30cb362553a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "len(unique_district_keys)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5fa5f7937e7f8591",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "len(long_district_alphanumerics)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9cb3b2665b921db8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(unique_district_keys)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e79f0ee5eb98db56",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open('../../vietadminunits/data/parse.pkl', 'wb') as f:\n",
    "    pickle.dump((duplicated_district_keys, duplicated_district_province_keys, duplicated_ward_keys, duplicated_ward_district_keys, province_keys_1, province_keys_2, province_keys_3, province_map, district_map, ward_map, double_check_provinces, double_check_districts, half_district_keys, long_district_alphanumerics, unique_district_keys), f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "755934acf0047162",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
