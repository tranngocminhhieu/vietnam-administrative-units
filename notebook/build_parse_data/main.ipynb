{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Build parse data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fcc7247bf129d2a6"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-20T20:47:17.914509Z",
     "start_time": "2024-09-20T20:47:16.995499Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append('../../vietadminunits')\n",
    "from utils import to_alphanumeric, to_key\n",
    "from parse import parse_address"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Functions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f575361c4c167ffd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def add_province_key(df_province, province_english, province_key):\n",
    "    if not df_province[df_province.province_english==province_english].shape[0]:\n",
    "        raise ValueError(f'{province_english} is not exist in province_english')\n",
    "    elif df_province[(df_province.province_english==province_english) & (df_province.province_key==province_key)].shape[0]:\n",
    "        raise ValueError(f'{province_key} is exist in province_key')\n",
    "    \n",
    "    df_new = df_province.loc[df_province.province_english==province_english].head(1)\n",
    "    df_new['province_key'] = province_key\n",
    "    df_province = pd.concat([df_province, df_new])\n",
    "    return df_province"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c90c8f7661a749a1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def add_district_key(df_district, province_english, district_english, district_key):\n",
    "    if not df_district[df_district.province_english==province_english].shape[0]:\n",
    "        raise ValueError(f'{province_english} is not exist in province_english')\n",
    "    elif not df_district[(df_district.province_english==province_english) & (df_district.district_english==district_english)].shape[0]:\n",
    "        raise ValueError(f'{district_english} is not exist in district_english of {province_english}')\n",
    "    elif df_district[(df_district.province_english==province_english) & (df_district.district_english==district_english) & (df_district.district_key==district_key)].shape[0]:\n",
    "        raise ValueError(f'{district_key} is exist in district_key of {province_english}, {district_english}')\n",
    "    \n",
    "    df_new = df_district.loc[(df_district.province_english==province_english) & (df_district.district_english==district_english)].head(1)\n",
    "    df_new['district_key'] = district_key\n",
    "    df_district = pd.concat([df_district, df_new])\n",
    "    return df_district"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32b1939b896a8f98",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def add_ward_key(df_ward, province_english, district_english, ward_english, ward_key):\n",
    "    if not df_ward[df_ward.province_english==province_english].shape[0]:\n",
    "        raise ValueError(f'{province_english} is not exist in province_english')\n",
    "    \n",
    "    elif not df_ward[(df_ward.province_english==province_english) & (df_ward.district_english==district_english)].shape[0]:\n",
    "        raise ValueError(f'{district_english} is not exist in district_english of {province_english}')\n",
    "    \n",
    "    elif not df_ward[(df_ward.province_english==province_english) & (df_ward.district_english==district_english) & (df_ward.ward_english==ward_english)].shape[0]:\n",
    "        raise ValueError(f'{ward_english} is not exist in ward_english of {province_english}, {district_english}')\n",
    "    \n",
    "    elif df_ward[(df_ward.province_english==province_english) & (df_ward.district_english==district_english) & (df_ward.ward_english==ward_english) & (df_ward.ward_key==ward_key)].shape[0]:\n",
    "        raise ValueError(f'{ward_key} is exist in ward_key of {province_english}, {district_english}, {ward_english}')\n",
    "    \n",
    "    df_new = df_ward.loc[(df_ward.province_english==province_english) & (df_ward.district_english==district_english) & (df_ward.ward_english==ward_english)].head(1)\n",
    "    df_new['ward_key'] = ward_key\n",
    "    df_ward = pd.concat([df_ward, df_new])\n",
    "    return df_ward"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f4875c92642bdac",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Base dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be8d4555bb973d69"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/output/vietnam_administrative_units.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3dd43d782abe18a1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e537352f45630d46",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c7865b3c62ec036",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df['province_key'] = df['province'].apply(to_key, args=(1,))\n",
    "df['district_key'] = df['short_district'].apply(to_key, args=(2,))\n",
    "df['ward_key'] = df['short_ward'].apply(to_key, args=(3,))\n",
    "df['district_level_english'].fillna('', inplace=True)\n",
    "df['ward_level_english'].fillna('', inplace=True)\n",
    "df['province_alphanumeric'] = df['long_province'].apply(to_alphanumeric)\n",
    "df['district_alphanumeric'] = df['long_district'].apply(to_alphanumeric)\n",
    "df['ward_alphanumeric'] = df['long_ward'].apply(to_alphanumeric)\n",
    "df['province_alphanumeric_english'] = df['long_province_english'].apply(to_alphanumeric)\n",
    "df['district_alphanumeric_english'] = df['long_district_english'].apply(to_alphanumeric)\n",
    "df['ward_alphanumeric_english'] = df['long_ward_english'].apply(to_alphanumeric)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c5d99ae8b4ce619",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create keyword lists that are duplicated district_keyword\n",
    "\n",
    "Eg: Hà Tĩnh has Huyện Kỳ Anh and Thị xã Kỳ Anh."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "635b3efaecaa2f6e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "district_count = df[['province', 'long_district', 'district_key']].drop_duplicates()[['province', 'district_key']].value_counts().reset_index()\n",
    "duplicated_districts = district_count[district_count['count'] > 1]['district_key'].tolist()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5ac0bb1ca84818b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_duplicated_districts = df[df.district_key.isin(duplicated_districts)][['long_province', 'long_district' ,'province_key','district_key']].drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c19e9d87e6f766ee",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_duplicated_districts"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "20495c948239a612",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "My idea: We will use their wards to decide their district level.\n",
    "\n",
    "To make sure this idea is valid, I will check whether they have some wards with the same ward_key"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f9ecba309f4fde6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for district_key in duplicated_districts:\n",
    "    long_districts = df[df.district_key==district_key]['long_district'].unique().tolist()\n",
    "    a = []\n",
    "    b = []\n",
    "    long_district_a = long_districts[0]\n",
    "    long_district_b = long_districts[1]\n",
    "    ward_key_a = df[df.long_district==long_district_a]['ward_key'].unique().tolist()\n",
    "    ward_key_b = df[df.long_district==long_district_b]['ward_key'].unique().tolist()\n",
    "    common = list(set(a) & set(b))\n",
    "    if common:\n",
    "        print(district_key, 'has duplicated ward_key')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e01c31372792a7a0",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nice! We also have default option if there are no ward in the address, I use Google Trend to decide default district level."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b8a1edeb2c2f550"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Pickle\n",
    "duplicated_district_province_keys = df_duplicated_districts['province_key'].unique().tolist()\n",
    "\n",
    "# Use Google Trend and search to decide level\n",
    "duplicated_district_keys = {\n",
    "    'kyanh': {'default':'Town'},\n",
    "    'cailay': {'default':'Town'},\n",
    "    'duyenhai': {'default':'District'},\n",
    "    'caolanh': {'default':'City'},\n",
    "    'hongngu': {'default':'City'},\n",
    "    'longmy': {'default':'District'}\n",
    "}\n",
    "\n",
    "for district_key in duplicated_districts:\n",
    "    df_temp = df[df.district_key == district_key]\n",
    "    level_data = {}\n",
    "    levels = df_temp.district_level_english.unique().tolist()\n",
    "    for district_level_english in levels:\n",
    "        ward_keys = df_temp[df_temp.district_level_english==district_level_english]['ward_key'].unique().tolist()\n",
    "        level_data[district_level_english] = ward_keys\n",
    "        duplicated_district_keys[district_key]['levels'] = level_data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ebaf93ff2e5143f8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print('Provinces:', duplicated_district_province_keys, '\\n')\n",
    "print('Districts:', duplicated_district_keys)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "969432cad1a18d05",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "At this step, we collect these data to save to module data:\n",
    "- `duplicated_district_province_keys`\n",
    "- `duplicated_district_keys`"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2baa6d4821fcd8f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Find district alias keywords\n",
    "\n",
    "Data source: [Danh sách các đơn vị hành chính cấp huyện không còn tồn tại](https://vi.wikipedia.org/wiki/Danh_s%C3%A1ch_%C4%91%C6%A1n_v%E1%BB%8B_h%C3%A0nh_ch%C3%ADnh_c%E1%BA%A5p_huy%E1%BB%87n_c%E1%BB%A7a_Vi%E1%BB%87t_Nam#Danh_s%C3%A1ch_c%C3%A1c_%C4%91%C6%A1n_v%E1%BB%8B_h%C3%A0nh_ch%C3%ADnh_c%E1%BA%A5p_huy%E1%BB%87n_kh%C3%B4ng_c%C3%B2n_t%E1%BB%93n_t%E1%BA%A1i)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c28e8aa6fe18695f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def check_containing_keyword(district, change):\n",
    "    if change.count(district) == 2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c5d412180812c8b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_district_change = pd.read_csv('../../data/input/district_change.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8efe6538132de5f9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_district_change.dropna(inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3578e97ca63fe0ea",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_district_change['containing_keyword_two_times'] = df_district_change.apply(lambda x: check_containing_keyword(x.old_district, x.change), axis=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68f06a1db08917db",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_change = df_district_change[(df_district_change.change.fillna('').str.contains('sáp nhập|đổi tên')) & ~(df_district_change.change.fillna('').str.contains('một phần'))].copy()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e5b6ba08e73c721",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_change"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eea28fdda69f98dc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_split = df_district_change[df_district_change.containing_keyword_two_times==1].copy()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9d2d3aad4a2a39",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_split"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5750584e37cad3c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# This is a particular case that is duplicated district_key\n",
    "df_split = df_split[df_split.old_district!='Tân Uyên'].copy()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c7a2eb62ed3466f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Use Google Trend to decide new district\n",
    "df_split.loc[df_split.old_district=='Mỏ Cày', 'district_english'] = 'Mo Cay Nam'\n",
    "df_split.loc[df_split.old_district=='Hàm Thuận', 'district_english'] = 'Ham Thuan Nam'\n",
    "df_split.loc[df_split.old_district=='Từ Liêm', 'district_english'] = 'Nam Tu Liem'\n",
    "df_split.loc[df_split.old_district=='Trà My', 'district_english'] = 'Nam Tra My'\n",
    "df_split.loc[df_split.old_district=='Gò Công', 'district_english'] = 'Go Cong Tay'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abbc8e9419a12522",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_split"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d903322b5fea2f07",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def find_new_district_english(text):\n",
    "    au = parse_address(text, 2)\n",
    "    return au.district_english"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "130ede664251b2e8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def prepare_address(province, change):\n",
    "    address = re.sub(f'.* thành ', '', change) + ', ' + province\n",
    "    return address"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f200dbeb4366198",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_province_english(text):\n",
    "    au = parse_address(text, 1)\n",
    "    return au.province_english"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ceecd16d80a84002",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_change['address'] = df_change.apply(lambda row: prepare_address(row.province, row.change), axis=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80c5a2144f1bf8c8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_change"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c45627e1f657c72",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_change = df_change[df_change.old_district!='Thủ Đức (quận)'].copy()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5503e7c5bfa6b34d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_change['district_english'] = df_change.address.apply(find_new_district_english)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dda40bcde7ec5f67",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "After doing research, I found district_english `None` are fine, because they are moved to another province or revert it's changing."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7dec248193b5f14"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_change.dropna(inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7572f49ea48f23f5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_change.dropna(inplace=True)\n",
    "df_all = pd.concat([df_change, df_split])\n",
    "df_all['province_english'] = df_all.province.apply(create_province_english)\n",
    "df_all['district_key'] = df_all.old_district.apply(to_key, args=(2,))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf65efe35a723fbf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_all"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4792130c8b49ee00",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "district_alias_keys = [tuple(i) for i in  df_all[['province_english', 'district_english', 'district_key']].values.tolist()]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "feef68d87866d4bd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "district_alias_keys"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac47c7c1aac815c6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_split['old_district_key'] = df_split['old_district'].apply(to_key, args=(2,))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4b06b1dd2e7947e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Pickle\n",
    "half_district_keys = {}\n",
    "for old_district_key in df_split['old_district_key'].unique().tolist():\n",
    "    df_temp = df[df.district_key.str.contains(old_district_key)]\n",
    "    district_keys =  df_temp.district_key.unique().tolist()\n",
    "    district_key_data = {}\n",
    "    for district_key in district_keys:\n",
    "        district_key_data[district_key] = df_temp[df_temp.district_key==district_key]['ward_key'].unique().tolist()\n",
    "    half_district_keys[old_district_key] = district_key_data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b76199d1d5d1f288",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "half_district_keys"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b173b4d1961a139e",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "After this step, we got `half_district_keys` for module data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ae4517edb1157b4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create keyword lists that are duplicated ward_keyword"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b2e02ce611ed152"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ward_count = df[['long_province', 'long_district', 'short_ward']].value_counts().reset_index()\n",
    "df_duplicated_wards = ward_count[ward_count['count'] > 1].copy()\n",
    "df_duplicated_wards.sort_values(by=['long_province', 'long_district', 'short_ward'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36d6afa7d76816ea",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_duplicated_wards = df[(df.long_province.isin(df_duplicated_wards.long_province)) & (df.long_district.isin(df_duplicated_wards.long_district)) & (df.short_ward.isin(df_duplicated_wards.short_ward))][['province', 'long_district', 'ward','ward_level_english', 'district_key', 'ward_key']]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d92faf473be44bb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_duplicated_wards"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22024ec0b6c0c44f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Following Google Trend, \"xã ...\" is higher \"thị trấn ...\" significant. But \"phường ...\" is higher than \"xã ...\" and we have only one ward in the list."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae2dd5d209a6b301"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Pickle\n",
    "duplicated_ward_keys = df_duplicated_wards.ward_key.unique().tolist()\n",
    "duplicated_ward_district_keys = df_duplicated_wards.district_key.unique().tolist()\n",
    "\n",
    "new_data = {}\n",
    "\n",
    "for ward_key in duplicated_ward_keys:\n",
    "    levels = df_duplicated_wards[df_duplicated_wards.ward_key == ward_key]['ward_level_english'].tolist()\n",
    "    if 'Ward' in levels:\n",
    "        ward_level = 'Ward'\n",
    "    elif 'Commune' in levels:\n",
    "        ward_level = 'Commune'\n",
    "    else:\n",
    "        ward_level = 'Town'\n",
    "    new_data[ward_key] = ward_level\n",
    "    \n",
    "duplicated_ward_keys = new_data.copy()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b25c9f8f0985e16",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print('Districts:' ,duplicated_ward_district_keys)\n",
    "print('Wards:', duplicated_ward_keys)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2e88418396fed1f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "After this step, we got these data for module:\n",
    "- `duplicated_ward_keys`\n",
    "- `duplicated_ward_district_keys`"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b54e61378506981"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sort province_key to prioritize some provinces\n",
    "- Some province has districts, or wards that are the same keyword with another province.\n",
    "- We need to run module_testing to check whether any address is wrong > Use ChatGPT to sort keywords > Add manually if we found new wrong keyword.\n",
    "\n",
    "For example:\n",
    "- 'Huyện Quang Bình, Tỉnh Hà Giang' -> quangbinh\n",
    "- 'Huyện Phù Yên, Tỉnh Sơn La' -> phuyen\n",
    "- 'Huyện Văn Giang, Tỉnh Hưng Yên' -> angiang\n",
    "- 'Huyện Quảng Ninh, Tỉnh Quảng Bình' -> quangninh\n",
    "- Bac Lieu, Hoa Binh District -> hoabinh"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1e920e2186097aa"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "province_keys = df.province_key.unique().tolist()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55326a74baf22559",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def find_province_key_match(text):\n",
    "    for province_key in province_keys:\n",
    "        if province_key in text:\n",
    "            return province_key"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3eab46036d6d2a6c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "match_district = df[df.district_key.str.contains('|'.join(province_keys))][['province', 'district', 'province_key','district_key']].drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "349b471c9a67b87a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "match_ward = df[(~df.ward.isna()) & (df.ward_key.str.contains('|'.join(province_keys)))][['province', 'ward', 'province_key','ward_key']].drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2101b458daa5bb6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "match_district['match_province_key'] = match_district['district_key'].apply(find_province_key_match)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7a235615b092279",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "match_ward['match_province_key'] = match_ward['ward_key'].apply(find_province_key_match)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90a5364c7d279ffa",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "match_district = match_district[match_district.province_key != match_district.match_province_key]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2e38920a24963e7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "match_district"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd8f0dcf755e4a76",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "match_ward = match_ward[match_ward.province_key != match_ward.match_province_key]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e8dabbad58575bc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "match_ward"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a286547162f15df7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Should not use list(set()) because it will re-order\n",
    "province_order = []\n",
    "\n",
    "for row in match_district.itertuples():\n",
    "    if row.province_key not in province_order:\n",
    "        province_order.append(row.province_key)\n",
    "    if row.match_province_key not in province_order:\n",
    "        province_order.append(row.match_province_key)\n",
    "        \n",
    "for row in match_ward.itertuples():\n",
    "    if row.province_key not in province_order:\n",
    "        province_order.append(row.province_key)\n",
    "    if row.match_province_key not in province_order:\n",
    "        province_order.append(row.match_province_key)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c8687cc82b480bf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "province_key_order = {}\n",
    "for index, province_key in enumerate(province_order):\n",
    "    province_key_order[province_key] = index + 1\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5129d80c0bf4f652",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(province_key_order)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21551ef031d6de7b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df['province_key_order'] = df['province_key'].map(province_key_order).fillna(0)\n",
    "\n",
    "df.sort_values(by='province_key_order', inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8a12456da334b0",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Add alias province_keyword\n",
    "- We should not add \"hn\" because it will cause many wrong matches. I will replace `\\bhn\\b` to `\\bha noi\\b` of the address, this step is in `parse.py`"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "398029c04e639d54"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_province = df[[col for col in df.columns if 'province' in col]].drop_duplicates()\n",
    "\n",
    "province_alias_keys = [\n",
    "    ('Ho Chi Minh', 'hcm')\n",
    "]\n",
    "\n",
    "for key in province_alias_keys:\n",
    "    province_english, province_key = key\n",
    "    df_province = add_province_key(df_province, province_english, province_key)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e3e541cf6cffa27",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Add alias district_keyword\n",
    "There are many district was changed it's name or be combined with other districts. For instance: Quan 9 > Thanh pho Thu Duc.\n",
    "\n",
    "Use `find_district_alias_keywords.ipynb` to create a list of tuples."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7bc50feab7e6e99d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_district = df[['province_english'] + [col for col in df.columns if 'district' in col]].drop_duplicates()\n",
    "\n",
    "for key in district_alias_keys:\n",
    "    province_english, district_english, district_key = key\n",
    "    df_district = add_district_key(df_district, province_english, district_english, district_key)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b4ed620017edf0a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "district_alias_keys"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a556a6c8e8fab88",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some districts contain \"quan\" with number in their keywords. We need to make a copy and replace \"quan\" to \"district\"."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "329dfb4242377ef8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "hcm_districts = df_district[df_district['district_key'].str.contains(r'quan\\d{1,2}')].copy()\n",
    "hcm_districts['district_key'] = hcm_districts['district_key'].str.replace('quan', 'district')\n",
    "df_district = pd.concat([df_district, hcm_districts])\n",
    "hcm_districts['district_key'] = hcm_districts['district_key'].str.replace('district', 'q.')\n",
    "df_district = pd.concat([df_district, hcm_districts])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e3870492482a94a",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create alias ward_key\n",
    "Some wards contain \"phuong\" with number in their keywords. We need to make a copy and replace \"phuong\" to \"ward\".\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5cb518d7ed6fa887"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_ward = df[['province_english', 'district_english'] + [col for col in df.columns if 'ward' in col]].drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e14acc61d1d33a8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "number_wards = df_ward[df_ward['ward_key'].fillna('').str.contains(r'phuong\\d{1,2}')].copy()\n",
    "number_wards['ward_key'] = number_wards['ward_key'].str.replace('phuong', 'ward')\n",
    "df_ward = pd.concat([df_ward, number_wards])\n",
    "number_wards['ward_key'] = number_wards['ward_key'].str.replace('ward', 'p.')\n",
    "df_ward = pd.concat([df_ward, number_wards])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7e66b3d54b9f90d",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create province_keys lists\n",
    "We will prioritize provinces that are not in district_key or ward_key when searching a province_key in address."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50bfaf3078fc1682"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "province_keys = df_province['province_key'].tolist()\n",
    "\n",
    "# Pickle\n",
    "province_keys_1 = []\n",
    "province_keys_2 = []\n",
    "province_keys_3 = []\n",
    "\n",
    "district_keys = str(df.district_key.unique().tolist())\n",
    "ward_keys = str(df.ward_key.unique().tolist())\n",
    "for province_key in province_keys:\n",
    "    if (province_key not in district_keys) and (province_key not in ward_keys):\n",
    "        province_keys_1.append(province_key)\n",
    "    elif province_key not in ward_keys:\n",
    "        province_keys_2.append(province_key)\n",
    "    else:\n",
    "        province_keys_3.append(province_key)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1b5241edd87bf58",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "province_alphanumerics = df.province_alphanumeric.unique().tolist() + df.province_alphanumeric_english.unique().tolist()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ffe28823f4e1bbdb",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "After this step we got these data for module:\n",
    "- `province_keys_1`\n",
    "- `province_keys_2`\n",
    "- `province_keys_3`"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b457a549df7dc7ed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create mapping dictionaries\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa791b0587c8590a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Pickle\n",
    "province_map = {}\n",
    "\n",
    "for province_key in df_province.province_key.unique():\n",
    "    province = df_province[df_province['province_key'] == province_key]\n",
    "    province_record = province.to_dict(orient='records')[0]\n",
    "    province_map[province_key] = province_record\n",
    "    \n",
    "    \n",
    "for province_alphanumeric in df_province.province_alphanumeric.unique():\n",
    "    province = df_province[df_province['province_alphanumeric'] == province_alphanumeric]\n",
    "    province_record = province.to_dict(orient='records')[0]\n",
    "    province_map[province_alphanumeric] = province_record\n",
    "    \n",
    "    \n",
    "for province_alphanumeric_english in df_province.province_alphanumeric_english.unique():\n",
    "    province = df_province[df_province['province_alphanumeric_english'] == province_alphanumeric_english]\n",
    "    province_record = province.to_dict(orient='records')[0]\n",
    "    province_map[province_alphanumeric_english] = province_record"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dcb40691af26b797",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(province_map)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "655b12be0a2ce88a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Pickle\n",
    "district_map = {}\n",
    "\n",
    "for province_english in df_province.province_english.unique():\n",
    "    district_keys = {}\n",
    "    for district_key in df_district[df_district.province_english == province_english]['district_key'].unique():\n",
    "        district_levels = {}\n",
    "        for district_level_english in df_district[(df_district.province_english == province_english) & (df_district.district_key == district_key)]['district_level_english'].unique():\n",
    "            district = df_district[(df_district.province_english == province_english) & (df_district.district_key == district_key) & (df_district.district_level_english == district_level_english)]\n",
    "            district_record = district[[col for col in district.columns if 'district' in col]].to_dict('records')[0]\n",
    "            district_levels[district_level_english] = district_record\n",
    "        district_keys[district_key] = district_levels\n",
    "        \n",
    "    district_keys = dict(sorted(district_keys.items(), key=lambda item: len(item[0]), reverse=True))\n",
    "    \n",
    "    district_map[province_english] = district_keys"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "57ab1579066f41f5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(district_map['Ho Chi Minh'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "caddace33c6defe9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Pickle\n",
    "ward_map = {}\n",
    "\n",
    "for province_english in df_province.province_english.unique():\n",
    "    districts = {}\n",
    "    for district_english in df_district[df_district.province_english==province_english].district_english.unique():\n",
    "        wards = {}\n",
    "        for ward_key in df_ward[(df_ward.province_english==province_english) & (df_ward.district_english==district_english)].ward_key.dropna().unique():\n",
    "            ward_levels = {}\n",
    "            for ward_level_english in df_ward[(df_ward.province_english==province_english) & (df_ward.district_english==district_english) & (df_ward.ward_key==ward_key)].ward_level_english.unique():\n",
    "                ward = df_ward[(df_ward.province_english==province_english) & (df_ward.district_english==district_english) & (df_ward.ward_key==ward_key) & (df_ward.ward_level_english==ward_level_english)]\n",
    "                ward_record = ward[[col for col in ward.columns if 'ward' in col]].to_dict('records')[0]\n",
    "                ward_levels[ward_level_english] = ward_record\n",
    "            wards[ward_key] = ward_levels\n",
    "        wards = dict(sorted(wards.items(), key=lambda item: len(str(item[0])), reverse=True))\n",
    "        districts[district_english] = wards\n",
    "    ward_map[province_english] = districts"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0eceda7e27b697e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(ward_map['Ho Chi Minh']['Tan Binh'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c78473258c2ed315",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "After this step, we got these data for module:\n",
    "- `province_map`\n",
    "- `district_map`\n",
    "- `ward_map`"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85ec88362f0bea9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create double check dictionaries\n",
    "Some address will cause wrong mapping because they have ward_key is as same as other province's province_key.\n",
    "- Use **sub_2_create_double_check_keywords.ipynb** to get the data.\n",
    "- Note that after saving this data to module, we can not create the data again."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e9f3c281b5238c9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "double_check_provinces = {\n",
    "    'angiang': ['thainguyen', 'ninhbinh', 'thanhhoa'],\n",
    "    'hoabinh': ['thainguyen',\n",
    "    'langson',\n",
    "    'haiphong',\n",
    "    'thaibinh',\n",
    "    'dongnai',\n",
    "    'vinhlong',\n",
    "    'dongthap'],\n",
    "    'binhthuan': ['thainguyen', 'quangngai', 'binhdinh'],\n",
    "    'thanhhoa': ['langson', 'binhphuoc', 'travinh', 'kiengiang', 'haugiang'],\n",
    "    'thaibinh': ['langson', 'tayninh'],\n",
    "    'hagiang': ['thaibinh', 'thanhhoa'],\n",
    "    'quangbinh': ['thaibinh', 'thanhhoa'],\n",
    "    'sonla': ['ninhbinh', 'quangngai', 'khanhhoa'],\n",
    "    'khanhhoa': ['ninhbinh', 'kiengiang'],\n",
    "    'longan': ['thanhhoa', 'dongnai', 'vinhlong'],\n",
    "    'quangninh': ['thanhhoa'],\n",
    "    'vinhlong': ['quangtri'],\n",
    "    'haiduong': ['quangtri'],\n",
    "    'haiphong': ['quangtri'],\n",
    "    'binhduong': ['quangnam', 'quangngai', 'binhdinh'],\n",
    "    'binhdinh': ['quangnam'],\n",
    "    'hungyen': ['kiengiang']\n",
    "}\n",
    "\n",
    "# double_check_provinces = {} # testing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "583daf5f5624ebf6",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some address will cause wrong mapping because they have ward_key is as same as other district's district_key."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ce87f2d7eddb04a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "double_check_districts = {'unghoa': ['caugiay', 'chuongmy'],\n",
    " 'thanhtri': ['hoangmai'],\n",
    " 'thanhxuan': ['socson'],\n",
    " 'thanhoai': ['thanhtri'],\n",
    " 'thongnong': ['haquang'],\n",
    " 'tralinh': ['trungkhanh'],\n",
    " 'quanguyen': ['quanghoa'],\n",
    " 'chora': ['babe'],\n",
    " 'yenson': ['sonduong'],\n",
    " 'camduong': ['laocai'],\n",
    " 'muongla': ['phuyen', 'songma', 'sopcop'],\n",
    " 'tranyen': ['lucyen', 'yenbinh'],\n",
    " 'kyson': ['hoabinh', 'tanky'],\n",
    " 'chilang': ['langson', 'trangdinh'],\n",
    " 'honggai': ['halong'],\n",
    " 'hoanhbo': ['halong'],\n",
    " 'uongbi': ['mongcai'],\n",
    " 'halong': ['vandon'],\n",
    " 'haiduong': ['binhgiang'],\n",
    " 'anduong': ['lechan', 'duongkinh', 'thuynguyen', 'vinhbao'],\n",
    " 'catba': ['cathai'],\n",
    " 'phucu': ['hungyen'],\n",
    " 'myloc': ['namdinh'],\n",
    " 'dongson': ['thanhhoa', 'bimson'],\n",
    " 'hatrung': ['bathuoc'],\n",
    " 'thanhhoa': ['nhuxuan', 'benluc'],\n",
    " 'vinh': ['anhson', 'yenthanh', 'hoangmai'],\n",
    " 'yenthanh': ['thanhchuong'],\n",
    " 'anhson': ['thanhchuong', 'namdan'],\n",
    " 'thachha': ['hatinh'],\n",
    " 'huongthuy': ['hue'],\n",
    " 'giang': ['thangbinh', 'bactramy', 'nuithanh'],\n",
    " 'tramy': ['bactramy'],\n",
    " 'sontinh': ['sontay'],\n",
    " 'ducpho': ['moduc'],\n",
    " 'dakto': ['konray', 'tumorong'],\n",
    " 'dakha': ['tumorong'],\n",
    " 'dakpo': ['kongchro'],\n",
    " 'iapa': ['chuse'],\n",
    " 'krongbuk': ['krongpac'],\n",
    " 'phuocbinh': ['phuoclong'],\n",
    " 'hoathanh': ['chauthanh'],\n",
    " 'laithieu': ['thuanan'],\n",
    " 'thongnhat': ['bienhoa'],\n",
    " 'vinhan': ['vinhcuu'],\n",
    " 'binhchanh': ['thuduc'],\n",
    " 'tanphu': ['thuduc', 'quan7', 'cuchi'],\n",
    " 'tanthanh': ['mochoa', 'thuthua'],\n",
    " 'tanan': ['canduoc'],\n",
    " 'tanhung': ['chauthanh'],\n",
    " 'tanphuoc': ['gocongdong'],\n",
    " 'mocay': ['mocaynam'],\n",
    " 'thanhphu': ['giongtrom', 'binhdai'],\n",
    " 'cainhum': ['mangthit'],\n",
    " 'longho': ['mangthit'],\n",
    " 'chauphu': ['chaudoc'],\n",
    " 'anphu': ['phutan', 'tinhbien', 'chauthanh', 'thoaison'],\n",
    " 'anminh': ['chauthanh', 'uminhthuong'],\n",
    " 'vithanh': ['vithuy']}\n",
    "\n",
    "# double_check_districts = {} # tesing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e838dbdf6fd290df",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Support find province from unique districts\n",
    "\n",
    "Điều kiện 1: district_key not in ward_keys.\n",
    "Điều kiện 2: district_count = 1, sau khi đã drop_duplicated [province_key, district_key]\n",
    "Điều kiện 3: district_key not in province_keys của tỉnh khác.\n",
    "\n",
    "Nếu district_key = province_key của chính nó:\n",
    ">> Lấy danh sách long_district_alphanumerices (bao gồm Việt và English), nếu tồn tại trong address thì sau khi tìm được province_key sẽ không bị xóa province_key trong địa chỉ.\n",
    "\n",
    "\n",
    "Nếu district_key != province_key của chính nó, tức là unique tuyệt đối:\n",
    ">> Lấy danh sách unique_district_keys, nếu không tìm được province_key thì tìm unique_district_key để suy ngược ra province_key"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d73800f8313ff044"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/output/vietnam_administrative_units.csv')\n",
    "df['province_key'] = df['province'].apply(lambda x: to_key(x, 1))\n",
    "df['district_key'] = df['short_district'].apply(lambda x: to_key(x, 2))\n",
    "df['ward_key'] = df['short_ward'].apply(lambda x: to_key(x, 3))\n",
    "df['ward_alphanumeric'] = df['long_ward'].apply(to_alphanumeric)\n",
    "\n",
    "\n",
    "province_keys = df['province_key'].unique().tolist()\n",
    "district_keys = df['district_key'].unique().tolist()\n",
    "ward_keys = df['ward_key'].unique().tolist()\n",
    "ward_alphanumerics = df['ward_alphanumeric'].unique().tolist()\n",
    "str_ward_alphanumerics = str(ward_alphanumerics)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ebf91a6940e0943",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Add alias key. Eg: Quan 2, Quan 9 are Thu Duc\n",
    "for key in district_alias_keys:\n",
    "    province_english, district_english, district_key = key\n",
    "    df = add_district_key(df, province_english, district_english, district_key)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7611da640df96696",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_district_filter = df[~df.district_key.apply(lambda x: x in str_ward_alphanumerics)]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7071f69753bef92f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_district_filter_count = df_district_filter[['province_key', 'district_key']].drop_duplicates()['district_key'].value_counts().reset_index()\n",
    "one_district_keys = df_district_filter_count[df_district_filter_count['count']==1]['district_key'].tolist()\n",
    "df_district_filter = df_district_filter[df_district_filter.district_key.isin(one_district_keys)][['province_key', 'district_key', 'long_district', 'long_district_english']].drop_duplicates()\n",
    "\n",
    "def check_valid_district_key(district_key, province_key):\n",
    "    if district_key in province_keys and district_key != province_key:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "df_district_filter['is_valid_district_key'] = df_district_filter.apply(lambda x: check_valid_district_key(x['district_key'], x['province_key']), axis=1)\n",
    "df_district_filter = df_district_filter[df_district_filter.is_valid_district_key]\n",
    "df_district_filter['same_key'] = np.where(df_district_filter.province_key == df_district_filter.district_key, True, False)\n",
    "\n",
    "long_district_alphanumerics = []\n",
    "for row in df_district_filter[df_district_filter.same_key].itertuples():\n",
    "    long_district_alphanumerics.append(to_alphanumeric(row.long_district))\n",
    "    long_district_alphanumerics.append(to_alphanumeric(row.long_district).replace('thanhpho', 'tp.'))\n",
    "    long_district_alphanumerics.append(to_alphanumeric(row.long_district_english))\n",
    "    \n",
    "    \n",
    "unique_district_keys = {}\n",
    "for row in df_district_filter[~df_district_filter.same_key][['province_key', 'district_key']].drop_duplicates().itertuples():\n",
    "    unique_district_keys[row.district_key] = row.province_key\n",
    "    district_key = row.district_key\n",
    "    if re.search(r'^quan\\d{1,2}', district_key):\n",
    "        district_key = re.sub('^quan', 'q.', district_key)\n",
    "        unique_district_keys[district_key] = row.province_key"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2b4db8bf5dd5cfd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "len(long_district_alphanumerics)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f091f2a7f8420957",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "long_district_alphanumerics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2acdb3e7cd4f9e7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "len(unique_district_keys)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9607ff5a96564e72",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "unique_district_keys"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7daef7760b5a49eb",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Support find province from unique \"long\" districts"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f14467c7737f6b9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df['province_alphanumeric'] = df['long_province'].apply(to_alphanumeric)\n",
    "df['district_alphanumeric'] = df['long_district'].apply(to_alphanumeric)\n",
    "df['ward_alphanumeric'] = df['long_ward'].apply(to_alphanumeric)\n",
    "df['province_alphanumeric_english'] = df['long_province_english'].apply(to_alphanumeric)\n",
    "df['district_alphanumeric_english'] = df['long_district_english'].apply(to_alphanumeric)\n",
    "df['ward_alphanumeric_english'] = df['long_ward_english'].apply(to_alphanumeric)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a667c0208b841f2b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "province_alphanumerics = df['province_alphanumeric'].unique().tolist()\n",
    "district_alphanumerics = df['district_alphanumeric'].unique().tolist()\n",
    "ward_alphanumerics = df['ward_alphanumeric'].unique().tolist()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e931e01409036401",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_district_filter = df[~df.district_alphanumeric.isin(ward_alphanumerics)]\n",
    "df_district_filter_count = df_district_filter[['province_alphanumeric', 'district_alphanumeric']].drop_duplicates()['district_alphanumeric'].value_counts().reset_index()\n",
    "one_district_alphanumerics = df_district_filter_count[df_district_filter_count['count']==1]['district_alphanumeric'].tolist()\n",
    "df_district_filter = df_district_filter[df_district_filter.district_alphanumeric.isin(one_district_alphanumerics)][['province_key','province_alphanumeric', 'district_alphanumeric', 'long_district', 'long_district_english', 'district_key', 'district_alphanumeric_english']].drop_duplicates()\n",
    "\n",
    "def check_valid_district_alphanumeric(district_alphanumeric, province_alphanumeric):\n",
    "    if district_alphanumeric in province_alphanumerics and district_alphanumeric != province_alphanumeric:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "df_district_filter['is_valid_district_alphanumeric'] = df_district_filter.apply(lambda x: check_valid_district_alphanumeric(x['district_alphanumeric'], x['province_alphanumeric']), axis=1)\n",
    "df_district_filter = df_district_filter[df_district_filter.is_valid_district_alphanumeric]\n",
    "df_district_filter['same_alphanumeric'] = np.where(df_district_filter.province_alphanumeric == df_district_filter.district_alphanumeric, True, False)\n",
    "\n",
    "for row in df_district_filter[df_district_filter.same_alphanumeric].itertuples():\n",
    "    long_district_alphanumerics.append(to_alphanumeric(row.long_district))\n",
    "    long_district_alphanumerics.append(to_alphanumeric(row.long_district).replace('thanhpho', 'tp.'))\n",
    "    long_district_alphanumerics.append(to_alphanumeric(row.long_district_english))\n",
    "    \n",
    "    \n",
    "for row in df_district_filter[~df_district_filter.same_alphanumeric][['province_key', 'district_alphanumeric', 'district_key', 'district_alphanumeric_english']].drop_duplicates().itertuples():\n",
    "    if not row.district_key in unique_district_keys:\n",
    "        unique_district_keys[row.district_alphanumeric] = row.province_key\n",
    "        unique_district_keys[row.district_alphanumeric_english] = row.province_key\n",
    "        district_alphanumeric = row.district_alphanumeric\n",
    "        district_alphanumeric = re.sub('^quan', 'q.', district_alphanumeric)\n",
    "        district_alphanumeric = re.sub('^huyen', 'h.', district_alphanumeric)\n",
    "        district_alphanumeric = re.sub('^thanhpho', 'tp.', district_alphanumeric)\n",
    "        district_alphanumeric = re.sub('^thixa', 'tx.', district_alphanumeric)\n",
    "        unique_district_keys[district_alphanumeric] = row.province_key"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65d5d30cb362553a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "len(unique_district_keys)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5fa5f7937e7f8591",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "len(long_district_alphanumerics)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9cb3b2665b921db8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(unique_district_keys)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e79f0ee5eb98db56",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Support find province from \"not unique\" district_key\n",
    "\n",
    "Now we can parse \"Phuong 15 Quan Tan Binh\" but \"Phuong 15 Tan Binh\" is not, because \"tanbinh\" is a ward_key of another province.\n",
    "\n",
    "To reach this feature, we will check if any ward_key of the district is in the address, and the ward_key must be placed before the district_key.\n",
    "\n",
    "- Condition 1: ward_key_district_key is unique.\n",
    "- Condition 2: district_key not in `unique_district_keys`"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b40969de16fbd5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Data I want\n",
    "{\n",
    "    'tanbinh': {\n",
    "        'hochiminh': ['phuong1', 'phuong2', 'p.1', 'p.2', 'district1', 'district2'],\n",
    "        'otherprovincekey': [...]\n",
    "    }\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23aa8b423a305dbc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df['ward_key_district_key'] = df['ward_key'] + '_' + df['district_key']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b33525a977bfeea",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ward_key_district_key_count = df['ward_key_district_key'].value_counts().reset_index()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6f42dd0fe089728",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "unique_ward_key_district_keys = ward_key_district_key_count[ward_key_district_key_count['count']==1]['ward_key_district_key'].tolist()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9264d2424ca0410",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_unique_ward_key_district_keys = df[(df['ward_key_district_key'].isin(unique_ward_key_district_keys)) & (~df['district_key'].isin(unique_district_keys))]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "efe2d16fbcf29aa",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "not_unique_district_keys = {}\n",
    "for district_key in df_unique_ward_key_district_keys['district_key'].unique().tolist():\n",
    "    data = {}\n",
    "    tmp_province_keys = df_unique_ward_key_district_keys[df_unique_ward_key_district_keys['district_key']==district_key]['province_key'].unique().tolist()\n",
    "    for province_key in tmp_province_keys:\n",
    "        tmp_ward_keys = df_unique_ward_key_district_keys[(df_unique_ward_key_district_keys['district_key']==district_key) & (df_unique_ward_key_district_keys['province_key']==province_key)]['ward_key'].unique().tolist()\n",
    "        tmp_number_wards = [i for i in tmp_ward_keys if re.search('^phuong\\d{1,2}', i)]\n",
    "        for num_ward_key in tmp_number_wards:\n",
    "            tmp_ward_keys.append(num_ward_key.replace('phuong','district'))\n",
    "            tmp_ward_keys.append(num_ward_key.replace('phuong','p.'))\n",
    "        data[province_key] = tmp_ward_keys\n",
    "    not_unique_district_keys[district_key] = data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61d68de45b55583",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "not_unique_district_keys['tanbinh']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d0c08d05e763a5c5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "not_unique_district_keys['chauthanh']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8327b6fc9e7c861",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "len(province_keys)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27f632cca724e519",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "alphanumeric_long_wards = df[df.ward_key.isin(province_keys)].ward_alphanumeric.unique().tolist() + df[df.ward_key.isin(province_keys)].ward_alphanumeric_english.unique().tolist()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f0c8f748c98e5d4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "alphanumeric_long_wards"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ea2bc519fb16053",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Support "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff04fd742ba7ddc6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open('../../vietadminunits/data/parse.pkl', 'wb') as f:\n",
    "    pickle.dump((duplicated_district_keys, duplicated_district_province_keys, duplicated_ward_keys, duplicated_ward_district_keys, province_keys_1, province_keys_2, province_keys_3, province_map, district_map, ward_map, double_check_provinces, double_check_districts, half_district_keys, long_district_alphanumerics, unique_district_keys, not_unique_district_keys, alphanumeric_long_wards, province_alphanumerics), f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "755934acf0047162",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f65d7645c19b3424",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
